{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN score for cycleGAN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from evaluate.networks import fcn_8s\n",
    "from skimage.io import imread\n",
    "import torchvision.transforms as tvt\n",
    "import PIL\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FCN.networks import FCN8s, VGGNet\n",
    "from FCN.citydataset import city, classes_city, train_transforms\n",
    "\n",
    "from evaluate.metrics import FCNScore\n",
    "from evaluate import losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r\"./datasets/cyclegan/\"\n",
    "mode = r\"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground Truth FCN score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =1\n",
    "city_dataset = city(mode=mode,classes=classes_city)\n",
    "city_loader  = DataLoader(dataset=city_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNScore(torch.nn.Module):\n",
    "    def __init__(self, model=None, num_classes=21):\n",
    "        super(FCNScore, self).__init__()\n",
    "        self.model = model\n",
    "        self.name = 'fcn'\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input.cuda())\n",
    "            labels = output.softmax(dim=1).argmax(dim=1)\n",
    "        return losses.label_score(labels,target,self.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn = FCN8s(pretrained_net=VGGNet(requires_grad=False),n_class = len(classes_city)).cuda()\n",
    "# change path to the correct path\n",
    "fcn.load_state_dict(torch.load(r\"FCN/checkpoints/EXP_11/checkpoint.pth.tar\"))\n",
    "\n",
    "# CityScapes : FCN/checkpoints/EXP_11/checkpoint.pth.tar\n",
    "# Maps : CN/checkpoints/EXP_16/checkpoint.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_score = FCNScore(model = fcn, num_classes=len(classes_city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for i, batch in enumerate(city_loader):\n",
    "    ppa, pca, iou_acc =   fcn_score(batch['image'], batch['target'])\n",
    "    metrics.append(batch_size*np.array([ppa, pca, iou_acc]))\n",
    "metrics = np.array(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.std(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle Gan FCN score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be changed to the different paths\n",
    "folder = r\"results/{}/test_latest/images\"\n",
    "model = r\"horses_cyclegan_sn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleCity(Dataset):\n",
    "    def __init__(self, model, folder=folder, transforms=train_transforms, classes=classes_city):\n",
    "        super(CycleCity, self).__init__()\n",
    "        self.data_path = folder.format(model)\n",
    "        self.transforms = transforms\n",
    "        self.ims = list(filter(lambda x: 'fake_A' in x, os.listdir(folder.format(model))))\n",
    "        self.masks = list(map(lambda x: x.replace('fake_A', 'real_B'), self.ims))\n",
    "        self.classes = classes\n",
    "    def __len__(self):\n",
    "        return len(self.ims)\n",
    "    def make_mask(self, mask):\n",
    "        def find_cluster(vec, classes=self.classes):\n",
    "            rscores = np.zeros((256 * 256, len(classes)))\n",
    "            for i in range(len(classes)):\n",
    "                rscores[:, i] = np.linalg.norm(vec - np.repeat(classes[i].reshape(1, 3), 256 * 256, axis=0), axis=1)\n",
    "            vc = np.argmin(rscores, axis=1)\n",
    "            return vc\n",
    "\n",
    "        def find_cluster_torch(vec, classes=self.classes):\n",
    "            rscores = torch.zeros((256 * 256, len(classes)))\n",
    "            for i in range(len(classes)):\n",
    "                rscores[:, i] = torch.norm(\n",
    "                    torch.cuda.FloatTensor(vec.reshape(-1, 3)) - torch.cuda.FloatTensor(\n",
    "                        classes[i].reshape(1, 3)).repeat(256 * 256, 1),\n",
    "                    dim=1\n",
    "                )\n",
    "\n",
    "            vc = rscores.argmin(dim=1)\n",
    "            return vc\n",
    "        clusters = find_cluster_torch(mask.reshape(-1,3))\n",
    "        mask = clusters.view(256,256).type(torch.LongTensor)\n",
    "        return mask\n",
    "    def __getitem__(self, index):\n",
    "        I, M = imread(os.path.join(self.data_path,self.ims[index])), imread(os.path.join(self.data_path,self.masks[index]))\n",
    "        mask = self.make_mask(M)\n",
    "        if self.transforms is not None:\n",
    "            I = self.transforms(I)\n",
    "        return {'image':I, 'target':mask, 'im':self.ims[index]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "cycle_city = CycleCity(model=model)\n",
    "cycle_city_loader = DataLoader(dataset=cycle_city, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_metrics = []\n",
    "ims = []\n",
    "for i, batch in enumerate(cycle_city_loader):\n",
    "    ppa, pca, iou_acc =   fcn_score(batch['image'], batch['target'])\n",
    "    ims.append(batch['im'])\n",
    "    cycle_metrics.append(batch_size*np.array([ppa, pca, iou_acc]))\n",
    "cycle_metrics = np.array(cycle_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cycle_metrics.sum(axis = 0)/len(cycle_city))\n",
    "print(cycle_metrics.std(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(filter(lambda x: '14'== x[0][0][:2], zip(ims, cycle_metrics)))\n",
    "D = list(map(lambda x: [x[0][0], x[1][0], x[1][1], x[1][2]], data))\n",
    "DF[model] = pd.DataFrame(D).sort_values(by=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the model name to the one you want to evaluate\n",
    "\n",
    "def imbyim(DF):\n",
    "    df = dict()\n",
    "    for im in DF['horses_cyclegan'].keys():\n",
    "        values = np.zeros(4)\n",
    "        for key in DF:\n",
    "            if 'pretrained' in key:\n",
    "                print(DF[key][DF[key][\"0\"] == im][1])\n",
    "                values[0] = DF[key][DF[key][0] == im][1]\n",
    "            elif 'sn' in key:\n",
    "                values[3] = DF[key][DF[key][0] == im][1]\n",
    "            elif 'wgan' in key:\n",
    "                values[2] = DF[key][DF[key][0] == im][1]\n",
    "            else:\n",
    "                values[1] = DF[key][DF[key][0] == im][1]\n",
    "            df[im] = pd.DataFrame(values, columns = ['PreTrained', 'Baseline', 'WGANGP', 'SN'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.DataFrame(np.hstack((DF[key][1].values.reshape(-1,1) for key in DF)).T, columns = DF['cityscapes_label2photo_pretrained'][0].values)\n",
    "D.index = ['PreTrained', 'Baseline', 'WGANGP', 'SN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: green' if v else '' for v in is_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.style.apply(highlight_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
