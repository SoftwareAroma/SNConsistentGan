{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO \n",
    "\n",
    "* Train epoch function\n",
    "* print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from networks import fcn_8s\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citydataset import city, cityscapes_classes, classes_city, maps_classes, facades_classes\n",
    "from loss import cross_entropy2d,CrossEntropyLoss2d\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r\"./datasets/cycle_gan/\"\n",
    "mode = r\"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = city(mode = \"train\", classes=maps_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.vgg import VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ranges = {\n",
    "    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
    "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
    "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
    "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
    "}\n",
    "\n",
    "# cropped version from https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n",
    "cfg = {\n",
    "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class VGGNet(VGG):\n",
    "    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
    "        super().__init__(make_layers(cfg[model]))\n",
    "        self.ranges = ranges[model]\n",
    "\n",
    "        if pretrained:\n",
    "            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
    "\n",
    "        if not requires_grad:\n",
    "            for param in super().parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        if remove_fc:  # delete redundant fully-connected layer params, can save memory\n",
    "            del self.classifier\n",
    "\n",
    "        if show_params:\n",
    "            for name, param in self.named_parameters():\n",
    "                print(name, param.size())\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = {}\n",
    "\n",
    "        # get the output of each maxpooling layer (5 maxpool in VGG net)\n",
    "        for idx in range(len(self.ranges)):\n",
    "            for layer in range(self.ranges[idx][0], self.ranges[idx][1]):\n",
    "                x = self.features[layer](x)\n",
    "            output[\"x%d\"%(idx+1)] = x\n",
    "\n",
    "        return output\n",
    "\n",
    "class FCN8s(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_net, n_class):\n",
    "        super().__init__()\n",
    "        self.n_class = n_class\n",
    "        self.pretrained_net = pretrained_net\n",
    "        self.relu    = torch.nn.ReLU(inplace=True)\n",
    "        self.deconv1 = torch.nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn1     = torch.nn.BatchNorm2d(512)\n",
    "        self.deconv2 = torch.nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn2     = torch.nn.BatchNorm2d(256)\n",
    "        self.deconv3 = torch.nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn3     = torch.nn.BatchNorm2d(128)\n",
    "        self.deconv4 = torch.nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn4     = torch.nn.BatchNorm2d(64)\n",
    "        self.deconv5 = torch.nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn5     = torch.nn.BatchNorm2d(32)\n",
    "        self.classifier = torch.nn.Conv2d(32, n_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.pretrained_net(x)\n",
    "        x5 = output['x5']  # size=(N, 512, x.H/32, x.W/32)\n",
    "        x4 = output['x4']  # size=(N, 512, x.H/16, x.W/16)\n",
    "        x3 = output['x3']  # size=(N, 256, x.H/8,  x.W/8)\n",
    "\n",
    "        score = self.relu(self.deconv1(x5))               # size=(N, 512, x.H/16, x.W/16)\n",
    "        score = self.bn1(score + x4)                      # element-wise add, size=(N, 512, x.H/16, x.W/16)\n",
    "        score = self.relu(self.deconv2(score))            # size=(N, 256, x.H/8, x.W/8)\n",
    "        score = self.bn2(score + x3)                      # element-wise add, size=(N, 256, x.H/8, x.W/8)\n",
    "        score = self.bn3(self.relu(self.deconv3(score)))  # size=(N, 128, x.H/4, x.W/4)\n",
    "        score = self.bn4(self.relu(self.deconv4(score)))  # size=(N, 64, x.H/2, x.W/2)\n",
    "        score = self.bn5(self.relu(self.deconv5(score)))  # size=(N, 32, x.H, x.W)\n",
    "        score = self.classifier(score)                    # size=(N, n_class, x.H/1, x.W/1)\n",
    "\n",
    "        return score # size=(N, n_class, x.H/1, x.W/1)\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [torch.nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = torch.nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, torch.nn.BatchNorm2d(v), torch.nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, torch.nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return torch.nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [torch.nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = torch.nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, torch.nn.BatchNorm2d(v), torch.nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, torch.nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return torch.nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGGNet(requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = FCN8s(pretrained_net=vgg_model, n_class=len(maps_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the path to where its saved\n",
    "fp.load_state_dict(torch.load(r\"checkpoints/EXP_/checkpoint.pth.tar\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def find_cluster(vec, classes=classes):\n",
    "    rscores = np.zeros((256 * 256, len(classes)))\n",
    "    for i in range(len(classes)):\n",
    "        rscores[:, i] = np.linalg.norm(vec - np.repeat(classes[i].reshape(1, 3), 256 * 256, axis=0), axis=1)\n",
    "    vc = np.argmin(rscores, axis=1)\n",
    "    return vc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def find_cluster_torch(vec, classes=classes):\n",
    "    rscores = np.zeros((256 * 256, len(classes)))\n",
    "    rscores = torch.zeros((256*256,len(classes)))\n",
    "    for i in range(len(classes)):\n",
    "        rscores[:,i] = torch.norm(\n",
    "            torch.cuda.FloatTensor(vec.reshape(-1,3))-torch.cuda.FloatTensor(classes[i].reshape(1,3)).repeat(256*256,1),\n",
    "            dim=1\n",
    "        )\n",
    "\n",
    "    vc = rscores.argmin(dim = 1)\n",
    "    return vc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "debut = time.time()\n",
    "vc_torch = find_cluster_torch(data.reshape(-1,3)).data.cpu().numpy()\n",
    "end =time.time()\n",
    "print(end-debut)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "debut = time.time()\n",
    "vc = find_cluster(data.reshape(-1,3))\n",
    "end =time.time()\n",
    "print(end-debut)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.imshow(classes[vc_torch.astype(int)].reshape(256,256,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = df[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "batch_size = 8\n",
    "epochs     = 500\n",
    "lr         = 1e-4\n",
    "momentum   = 0\n",
    "w_decay    = 1e-5\n",
    "step_size  = 50\n",
    "gamma = 0.5\n",
    "optimizer = torch.optim.RMSprop(fp.parameters(), lr=lr, momentum=momentum, weight_decay=w_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = df[0]\n",
    "i =batch['image'].cpu()\n",
    "m = batch['target'].cpu().data.numpy().astype(int)\n",
    "del batch\n",
    "plt.imshow(maps_classes[m].reshape(256,256,3))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = fp(i.unsqueeze(0))\n",
    "tfa = output.view(len(maps_classes),256*256).permute(1,0).argmax(dim=1).data.cpu().numpy().reshape(-1,1)\n",
    "plt.imshow(maps_classes[tfa].reshape(256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
